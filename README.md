# 📘 what-i-learned

This repository is a curated collection of concise, hands-on technical tutorials and learning notes as I explore cutting-edge topics in AI, systems, and software engineering.

Each subfolder contains:
- 🔍 Short concept overviews
- 🧠 Paper summaries
- 💻 Minimal reproducible code examples
- 🚀 Links to deeper resources or related projects

---

## 🌟 Topics Covered

| Topic          | Description                                             |
|----------------|---------------------------------------------------------|
| `vllm/`        | Efficient LLM inference with PagedAttention             |
| `cuda/`        | Basics of CUDA programming and GPU kernel writing       |
| `llms/`        | LLM architecture, KV cache, inference, and serving      |
| `rag/`         | Retrieval-Augmented Generation systems and pipelines    |
| `transformers/`| Transformer internals, attention mechanisms             |
| `optimization/`| Profiling, batching, and model-level speedups           |

More coming soon...

---

## 🔧 How to Use

1. Clone this repo:
   ```bash
   git clone https://github.com/sukanyasaha007/what-i-learned.git
   cd what-i-learned

# ğŸ“˜ what-i-learned

This repository is a curated collection of concise, hands-on technical tutorials and learning notes as I explore cutting-edge topics in AI, systems, and software engineering.

Each subfolder contains:
- ğŸ” Short concept overviews
- ğŸ§  Paper summaries
- ğŸ’» Minimal reproducible code examples
- ğŸš€ Links to deeper resources or related projects

---

## ğŸŒŸ Topics Covered

| Topic          | Description                                             |
|----------------|---------------------------------------------------------|
| `vllm/`        | Efficient LLM inference with PagedAttention             |
| `cuda/`        | Basics of CUDA programming and GPU kernel writing       |
| `llms/`        | LLM architecture, KV cache, inference, and serving      |
| `rag/`         | Retrieval-Augmented Generation systems and pipelines    |
| `transformers/`| Transformer internals, attention mechanisms             |
| `optimization/`| Profiling, batching, and model-level speedups           |

More coming soon...

---

## ğŸ”§ How to Use

1. Clone this repo:
   ```bash
   git clone https://github.com/sukanyasaha007/what-i-learned.git
   cd what-i-learned
